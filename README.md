# üè• Healthcare Real-Time Fraud Detection Pipeline (GCP)

A production-grade, real-time streaming fraud detection platform built on Google Cloud Platform (GCP) using Pub/Sub, Dataflow, BigQuery, Cloud Run, and Cloud Composer.

This project demonstrates how a healthcare payer processes claims in real time and detects fraudulent activity using machine learning with intelligent drift-based retraining.

**Project ID:** `health-data-analytics-477220`
**Status:** ‚úÖ All Services Deployed and Running
**Last Updated:** November 2025

## üìò 1. Overview

Health insurance companies process millions of claims daily. Detecting fraud early reduces:

- False payouts
- Fraudulent provider behavior
- Member risk
- Operational overhead

This project creates a real-time ML-powered fraud detection system that processes streaming claims and predicts fraud likelihood instantly, with automated drift detection and intelligent model retraining.

## üéØ 2. Objectives

- ‚úÖ Real-time claim ingestion via Pub/Sub
- ‚úÖ Validate and enrich claim events with Dataflow
- ‚úÖ Store claims in BigQuery for analytics
- ‚úÖ Train ML fraud model with SMOTE balancing
- ‚úÖ Perform real-time scoring via Cloud Run API
- ‚úÖ Orchestrate drift-based retraining with Composer
- ‚úÖ Provide monitoring & observability with Cloud Logging

## üöÄ 3. Deployed Services Status

All services are currently deployed and operational:

| Service | Status | Details |
|---------|--------|---------|
| **Pub/Sub** | ‚úÖ Running | Topic: `claims-ingest` |
| **Dataflow** | ‚úÖ Running | Job: `healthcare-claims-streaming` |
| **BigQuery** | ‚úÖ Active | Dataset: `aetna.claims_events_stream` |
| **Cloud Storage** | ‚úÖ Active | 7 buckets including models bucket |
| **Cloud Run API** | ‚úÖ Live | Service: `fraud-scoring-api` |
| **Cloud Composer** | ‚úÖ Running | Environment: `healthcare-analytics` |
| **Trained Models** | ‚úÖ Deployed | 3 versions in GCS (v1, v2, v3-smote) |

**Model Performance:**
- Current Model: `fraud-detector-v3-smote`
- ROC AUC: 0.5966
- Fraud Detection Rate: 36% @ threshold 0.3
- Precision: 56% @ threshold 0.5

## üèóÔ∏è 4. GCP Architecture

```mermaid
graph TB
    A[Claim Generator] -->|Publish| B[Pub/Sub Topic]
    B -->|Subscribe| C[Dataflow Pipeline]

    C -->|Write| D[BigQuery]

    D -->|Training Data| F[ML Training<br/>vertex/train.py]
    F -->|Save Model| G[GCS Models<br/>fraud-detector-v3-smote]

    G -->|Load Model| H[Cloud Run API<br/>fraud-scoring-api]

    I[Cloud Composer] -->|Daily Check| J{Drift Detection?}
    J -->|Yes - Drift Found| F
    J -->|No - Skip| K[Continue Monitoring]

    M[New Claims] -->|POST /predict| H
    H -->|Fraud Score| N[Investigation Queue]

    style D fill:#4285F4,stroke:#333,stroke-width:2px
    style G fill:#34A853,stroke:#333,stroke-width:2px
    style H fill:#FBBC04,stroke:#333,stroke-width:2px
    style I fill:#EA4335,stroke:#333,stroke-width:2px
```

## üß© 5. Components Used

### ‚úÖ Streaming & Integration

- **Pub/Sub** ‚Äî Ingest real-time claim events
- **Dataflow (Streaming)** ‚Äî Validate, enrich, deduplicate, fan-out

### ‚úÖ Storage

- **BigQuery** ‚Äî Raw ‚Üí curated ‚Üí predictions (analytical data warehouse)
- **GCS** ‚Äî Model storage and optional raw file landing

### ‚úÖ Machine Learning

- **Random Forest Classifier** with SMOTE balancing
- **Model Storage** in Cloud Storage
- **Drift Detection** using Kolmogorov-Smirnov test

### ‚úÖ Compute

- **Cloud Run**
  - Real-time Fraud Scoring API (Flask)
  - Endpoint: `fraud-scoring-api-<hash>-uc.a.run.app`

### ‚úÖ Orchestration & Ops

- **Cloud Composer (Airflow)** ‚Äî Drift-based retraining, data quality checks
- **Cloud Logging & Monitoring** ‚Äî Observability
- **IAM** ‚Äî Secure scoped identity

## üîÑ 6. End-to-End Data Flow

### 1Ô∏è‚É£ Claim Generation

Synthetic claims are generated using `claim_generator/claim_generator.py` and published to Pub/Sub topic `claims-ingest`.

### 2Ô∏è‚É£ Streaming ETL (Dataflow)

Dataflow pipeline `dataflow/pubsub_to_bigquery.py` performs:

- Schema validation
- Feature extraction
- Deduplication
- Real-time processing

Writes to:

- **BigQuery** `aetna.claims_events_stream` (analytical data warehouse)

### 3Ô∏è‚É£ Model Training

Training pipeline `vertex/train.py`:
- Loads data from BigQuery
- Applies SMOTE balancing (50/50 fraud/non-fraud)
- Trains Random Forest (200 trees, depth 15)
- Saves model to GCS bucket

**Current Model:** `fraud-detector-v3-smote`

### 4Ô∏è‚É£ Drift-Based Retraining (Intelligent)

Cloud Composer DAG `composer/dags/retrain_model_dag.py` runs **daily** to check:
- **Data Drift** (Kolmogorov-Smirnov test, p < 0.05)
- **New Fraud Cases** (>100 new cases)
- **Performance Drop** (ROC AUC drops >10%)

**Only retrains when necessary** ‚Äî saves ~75% of compute costs vs weekly schedule.

### 5Ô∏è‚É£ Real-Time Scoring

Cloud Run API `scoring_api/main.py`:
- Endpoint: `/predict`
- Loads model from GCS
- Returns fraud probability and risk level
- Response time: <500ms

### 6Ô∏è‚É£ Data Quality Monitoring

Daily DAG `composer/dags/data_quality_dag.py` monitors:
- Claim volume
- Error rates
- Fraud distribution

## üì¶ 7. Repository Structure

```
health_care_analytics_in_GCP/
‚îÇ
‚îú‚îÄ‚îÄ claim_generator/             # Synthetic claim generation
‚îÇ   ‚îú‚îÄ‚îÄ claim_generator.py
‚îÇ   ‚îî‚îÄ‚îÄ test_generator.py
‚îÇ
‚îú‚îÄ‚îÄ dataflow/                    # Streaming ETL pipeline
‚îÇ   ‚îú‚îÄ‚îÄ pubsub_to_bigquery.py   # Main Dataflow job
‚îÇ   ‚îú‚îÄ‚îÄ requirements.txt
‚îÇ   ‚îî‚îÄ‚îÄ deploy.ps1
‚îÇ
‚îú‚îÄ‚îÄ vertex/                      # ML training pipeline
‚îÇ   ‚îú‚îÄ‚îÄ train.py                # Main training script
‚îÇ   ‚îú‚îÄ‚îÄ predict.py              # Standalone prediction
‚îÇ   ‚îú‚îÄ‚îÄ MODEL_TRAINING_RESULTS.md
‚îÇ   ‚îî‚îÄ‚îÄ model/                  # Local model storage
‚îÇ
‚îú‚îÄ‚îÄ scoring_api/                 # Cloud Run API
‚îÇ   ‚îú‚îÄ‚îÄ main.py                 # Flask API
‚îÇ   ‚îú‚îÄ‚îÄ Dockerfile
‚îÇ   ‚îú‚îÄ‚îÄ requirements.txt
‚îÇ   ‚îî‚îÄ‚îÄ deploy.ps1
‚îÇ
‚îú‚îÄ‚îÄ composer/                    # Airflow orchestration
‚îÇ   ‚îú‚îÄ‚îÄ dags/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ retrain_model_dag.py      # Drift-based retraining
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ data_quality_dag.py       # Daily quality checks
‚îÇ   ‚îî‚îÄ‚îÄ README.md
‚îÇ
‚îú‚îÄ‚îÄ setup_bigquery.py            # BigQuery setup
‚îú‚îÄ‚îÄ load_training_data.py        # Initial data load
‚îî‚îÄ‚îÄ README.md                    # This file
```

## ‚úÖ 8. Why This Architecture Is Production-Grade

| Feature | Benefit |
|---------|---------|
| Real-time streaming | Fraud scoring within seconds |
| Drift-based retraining | Saves ~75% compute costs vs scheduled retraining |
| SMOTE balancing | Handles 97.42% class imbalance effectively |
| Dataflow enrichment | Ensures validated, clean, enriched data |
| BigQuery curated layers | Analytics-ready data warehouse |
| Cloud Run API | Auto-scaling, serverless scoring |
| Composer orchestration | Automated drift detection and retraining |
| KS Test drift detection | Statistical rigor for model staleness |

## üìä 9. Use Cases Enabled

| Use Case | Description |
|----------|-------------|
| Real-time fraud detection | Predict claims fraud risk instantly |
| Provider anomaly detection | Spot suspicious providers early |
| Member abuse detection | Identify patterns in over-utilization |
| SIU Team Investigation | Provide high-risk claims fast |
| Trend Analysis | Fraud patterns across states/procedures |

## üöÄ 10. Quick Start

### Prerequisites
- GCP Project with billing enabled
- Python 3.10+
- gcloud CLI configured

### Deployment Steps

All services are already deployed. To redeploy or test locally:

#### 1. Load Training Data
```bash
python load_training_data.py
```

#### 2. Train Model
```bash
cd vertex
python train.py --project-id=health-data-analytics-477220 \
                --dataset-id=aetna \
                --table-id=claims_events_stream \
                --bucket-name=health-data-analytics-477220-models \
                --model-name=fraud-detector-v3-smote \
                --limit=50000
```

#### 3. Deploy Dataflow Pipeline
```bash
cd dataflow
.\deploy.ps1
```

#### 4. Deploy Scoring API
```bash
cd scoring_api
.\deploy.ps1
```

#### 5. Generate Test Claims
```bash
cd claim_generator
$env:GCP_PROJECT = "health-data-analytics-477220"
$env:EVENTS_PER_SECOND = "5"
$env:RUN_DURATION_SECONDS = "120"
python claim_generator.py
```

#### 6. Test API
```bash
curl -X POST https://fraud-scoring-api-<hash>-uc.a.run.app/predict \
  -H "Content-Type: application/json" \
  -d '{
    "claim_amount": 15000,
    "patient_age": 45,
    "days_to_submission": 30,
    "claim_status": "PAID",
    "place_of_service": "ER"
  }'
```

## üìä 11. Key Results

### Model Performance (v3-SMOTE)
- **ROC AUC:** 0.5966 (+14% from baseline)
- **Fraud Detection Rate:** 36% @ threshold 0.3
- **Precision:** 56% @ threshold 0.5
- **Training Time:** <1 minute
- **Inference Time:** <500ms

### Cost Efficiency
- **Drift-based retraining:** ~75% cost savings vs weekly schedule
- **Cloud Run:** Pay-per-request autoscaling
- **Composer:** Small environment (~$150-200/month)
- **BigQuery:** First 1TB queries/month free

## üìö 12. Documentation

- **Model Training Results:** [vertex/MODEL_TRAINING_RESULTS.md](vertex/MODEL_TRAINING_RESULTS.md)
- **Composer DAGs:** [composer/README.md](composer/README.md)
- **Dataflow Pipeline:** [dataflow/README.md](dataflow/README.md)
- **Scoring API:** [scoring_api/README.md](scoring_api/README.md)

## üéØ 13. Presentation Demo Flow

For live demos, use this flow:

1. **Start Claim Generator** (2 min)
   ```powershell
   cd claim_generator
   $env:GCP_PROJECT = "health-data-analytics-477220"
   $env:EVENTS_PER_SECOND = "5"
   python claim_generator.py
   ```

2. **Show Pub/Sub** - Claims flowing through topic

3. **Show Dataflow** - Real-time processing with <1sec lag

4. **Query BigQuery** - Fresh data arriving
   ```sql
   SELECT claim_id, claim_amount, patient_age, 
          synthetic_label_is_fraud, ingest_ts
   FROM `health-data-analytics-477220.aetna.claims_events_stream`
   ORDER BY ingest_ts DESC
   LIMIT 20
   ```

5. **Test Scoring API** - Real-time fraud prediction

## ‚úÖ 14. Summary

This project demonstrates an end-to-end, production-grade healthcare fraud detection system using:
- **Real-time streaming** with Pub/Sub and Dataflow
- **Intelligent ML** with drift-based retraining
- **Scalable infrastructure** with Cloud Run and Composer
- **Cost optimization** with smart scheduling and serverless architecture

**Status:** All services deployed and operational in `health-data-analytics-477220`.
